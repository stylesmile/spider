# !/usr/bin/env python3
# -*- coding: utf-8 -*-

# @Time    : 2019/11/28 15:11
# @File    : å¤šè¯­è¨€é¡¹ç›®ä»»åŠ¡åˆ›å»ºfinally.py
# @Date    : 2019/11/28
# @Author  : Yuwenjun
# @Desc    :


import hashlib
import re
import time

import pandas as pd
import pymysql
from pymongo import MongoClient

# db = pymysql.connect(host='192.168.0.37', user='will_art', passwd='jFHKm2i4rg4WqpMz', db='will_art')
# client = MongoClient("192.168.0.37", 27017)
# mongodb = client.tasks
# mongodb.authenticate('tasks', 'm6pCEPrTZI84Lvka')

db = pymysql.connect(host='39.97.250.105', user='root', passwd='db123456!', db='will_art', port=3305)
client = MongoClient("39.97.250.105", 27016)
mongodb = client.tasks
mongodb.authenticate('tasks', 'admin123456!')

mark_symbol = re.compile(r"[Û”,.:;?|()&!*@$%<>+-/'\"]")
special_symbol = re.compile(r"[#'ï¼‹ï¼Ã—Ã·ï¹¢ï¹£Â±ï¼=â–£â˜†â€¢ï¼Œã€‚â˜…ã€ğŸ˜‚ã€ã€‘ã€Šã€‹ï¼Ÿâ€œâ€â€˜â€™ï¼[]_`{|\u4e00-\u9fa5}~]+")


def get_content_md5(content):
    md5_value = hashlib.md5(content.encode("utf-8")).hexdigest()
    return md5_value


def insert_mysql(dataset_name, col_name, dataset_count, duration, type, mark_type):
    print('insert mysql start')
    cusor = db.cursor()
    current_time = int(time.time() * 1000)
    sql = 'INSERT INTO `dataset` (`dataset_name`,`col_name`,`dataset_count`,`duration`,`type`,`mark_type`,`status`,`created_at`,`updated_at`)' \
          ' VALUES ("{}","{}",{},{},{},{},0,{},{});'.format(dataset_name, col_name, dataset_count, duration, type,
                                                            mark_type, current_time, current_time)
    print(sql)
    try:
        # æ‰§è¡Œsqlè¯­å¥
        cusor.execute(sql)
        # æäº¤åˆ°æ•°æ®åº“æ‰§è¡Œ
        db.commit()
    except:
        print('æäº¤mysqlå¼‚å¸¸ï¼Œè¯·æ£€æŸ¥')
        # å¦‚æœå‘ç”Ÿé”™è¯¯åˆ™å›æ»š
        db.rollback()


def create_unique_index(col_name):
    col = mongodb[col_name]
    all_index = col.index_information()
    has_md5_index = all_index.get("md5_1", False)
    if has_md5_index:
        if all_index['md5_1'].get('unique', False):  # md5ä¸ºå”¯ä¸€ç´¢å¼•
            pass
        else:
            col.drop_index([("md5", 1)])
            col.create_index([("md5", 1)], unique=True)  # å°è¯•åˆ›å»ºå”¯ä¸€ç´¢å¼•
    else:
        col.create_index([("md5", 1)], unique=True)  # å°è¯•åˆ›å»ºå”¯ä¸€ç´¢å¼•


def build_content_dic(order, content, origin, category):
    content_dic = dict()
    # clear_content = mark_symbol.sub("", content.replace(" ", ""))  # å»æ‰ç©ºæ ¼ï¼Œæ ‡ç‚¹ç¬¦å·è®¡ç®—md5
    md5 = get_content_md5(content)
    current_time = int(time.time() * 1000)
    content_dic['order'] = order
    content_dic['content'] = content
    content_dic['labelStatus'] = 0
    content_dic['handleStatus'] = 0
    content_dic['origin'] = origin
    content_dic['source'] = 1
    content_dic['category'] = category
    content_dic['md5'] = md5
    content_dic['createAt'] = current_time
    return content_dic


def get_col_last_order(col_name):
    col = mongodb[col_name]
    if col.count() > 0:
        print("æ•°æ®é›†å·²å­˜åœ¨ï¼Œè¯·è¾“å…¥å…¶å®ƒåå­—")
        exit(1)
        ret = col.find({}).sort([("_id", -1)]).limit(1)
        return ret.get("order") + 1
    else:
        return 1


def main(input_path, col_name, dataset_name, header, sheet_name):
    print("--- script start ---")
    header = 0 if header else None
    if sheet_name:
        df = pd.read_excel(input_path, encoding="utf-8", header=header, sheet_name=sheet_name, engine="openpyxl")
    else:
        df = pd.read_excel(input_path, header=header, encoding="utf-8", engine="openpyxl")
    print("--- success read excel --- ")

    df = df.drop_duplicates(subset="content").dropna() if header else df.drop_duplicates().dropna()

    print("--- start write to mongo ---")
    create_unique_index(col_name)  # ç»™é›†åˆä¸­çš„md5å­—æ®µå»ºç«‹å”¯ä¸€ç´¢å¼•

    data_dic = dict()
    count = 0
    order = get_col_last_order(col_name)  # è·å–å½“å‰é›†åˆæœ€åä¸€æ¡æ•°æ®çš„order
    origin = input_path.split("/")[-1].split(".")[0]
    category = 0
    col_index = "content" if header else 0
    for row in df.iterrows():
        content = row[1][col_index].strip()
        # content = special_symbol.sub("", content)  # å»æ‰ç‰¹æ®Šç¬¦å·
        if not content:
            continue
        # origin = row[1]['origin']
        # category = row[1]['category']
        content_dict = build_content_dic(order, content, origin, category)

        if not content_dict:
            continue
        order += 1

        data_dic[content_dict.get("md5")] = content_dict
        if len(data_dic.keys()) > 1120:
            print("å•ä»»åŠ¡æ–‡æœ¬å¥æ•°è¿‡é•¿")
            exit(1)
        if len(data_dic.keys()) == 50000:
            count += 50000
            mongodb[col_name].insert_many([value for value in data_dic.values()], ordered=False)
            data_dic.clear()
        print(content_dict)
    count += len(data_dic.keys())
    if count < 1000:
        print("Excelæ–‡æœ¬å¥æ•°ä½äº1000å¥ï¼Œè¯·ç¡®è®¤æ˜¯å¦ç»§ç»­åˆ›å»º")
        ret = input("è¯·è¾“å…¥1æˆ–è€…å…¶å®ƒä»»æ„å€¼ç¡®è®¤æ˜¯å¦ç»§ç»­æ‰§è¡Œè„šæœ¬ï¼Œ1ä»£è¡¨ç»§ç»­æ‰§è¡Œï¼Œå…¶å®ƒå€¼ç»“æŸè„šæœ¬ï¼š")
        if ret != "1":
            print("è„šæœ¬ä¸­æ–­æ‰§è¡Œ")
            exit(1)
        else:
            print("ç­‰å¾…5ç§’åï¼Œè„šæœ¬ç»§ç»­æ‰§è¡Œ")
            time.sleep(5)
    mongodb[col_name].insert_many([value for value in data_dic.values()], ordered=False)
    insert_mysql(dataset_name, col_name, count, 0, 0, 5)
    data_dic.clear()
    print("--- script end æ’å…¥äº†>>{}<<æ¡æ•°æ® ---".format(count))


if __name__ == '__main__':
    input_path = input("è¯·è¾“å…¥Excelæ–‡ä»¶è·¯å¾„ï¼š")
    col_name = input("è¯·è¾“å…¥æ•°æ®é›†åç§°ï¼š")
    dataset_name = input("è¯·è¾“å…¥æ•°æ®é›†ä¸­æ–‡åï¼š")
    header = input("è¯·è¾“å…¥headerï¼ˆæ— è¡¨å¤´å›è½¦ï¼Œæœ‰è¡¨å¤´1ï¼‰ï¼š")
    sheet_name = input("è¯·è¾“å…¥sheet_nameåï¼š")
    if not all((input_path, col_name, dataset_name)):
        print("è¯·æ£€æŸ¥Excelè·¯å¾„ã€æ•°æ®é›†åå’Œä¸­æ–‡åå‚æ•°æ˜¯å¦ç¼ºå¤±")
        exit(1)
    main(input_path, col_name, dataset_name, header, sheet_name)

    # C:\Users\chenye\Desktop\test-cn-test.xlsx
    # col_test_cn_2019_1220_1  æµ‹è¯•ä¸­æ–‡2019_1220_1
